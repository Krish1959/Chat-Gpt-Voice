import React, { useState, useRef, useEffect } from 'react';
import { Mic, MicOff, Volume2, VolumeX, Send } from 'lucide-react';

export default function AvatarAgenticAI() {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isChatActive, setIsChatActive] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  
  const recognitionRef = useRef(null);
  const synthRef = useRef(window.speechSynthesis);
  const chatLogRef = useRef(null);
  const contextMemory = useRef([]);

  useEffect(() => {
    if (chatLogRef.current) {
      chatLogRef.current.scrollTop = chatLogRef.current.scrollHeight;
    }
  }, [messages]);

  const sendMessageToOpenAI = async (userMessage) => {
    try {
      // Keep last 3-4 messages for context
      const recentContext = contextMemory.current.slice(-6);
      
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${process.env.OPEN_AI_KEY || ''}`,
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: 'You are a helpful AI assistant for Avatar Agentic AI.' },
            ...recentContext,
            { role: 'user', content: userMessage }
          ],
          max_tokens: 500,
        }),
      });

      if (!response.ok) {
        throw new Error(`API Error: ${response.status}`);
      }

      const data = await response.json();
      const aiResponse = data.choices[0].message.content;

      // Update context memory
      contextMemory.current.push(
        { role: 'user', content: userMessage },
        { role: 'assistant', content: aiResponse }
      );

      // Keep only last 8 messages (4 exchanges)
      if (contextMemory.current.length > 8) {
        contextMemory.current = contextMemory.current.slice(-8);
      }

      return aiResponse;
    } catch (error) {
      console.error('OpenAI API Error:', error);
      return 'Sorry, I encountered an error connecting to the AI service. Please check your API key and try again.';
    }
  };

  const handleSendMessage = async () => {
    if (!input.trim() || !isChatActive) return;

    const userMessage = input.trim();
    setMessages(prev => [...prev, { role: 'user', content: userMessage }]);
    setInput('');
    setIsLoading(true);

    const aiResponse = await sendMessageToOpenAI(userMessage);
    
    setMessages(prev => [...prev, { role: 'assistant', content: aiResponse }]);
    setIsLoading(false);

    if (isSpeaking) {
      speakText(aiResponse);
    }
  };

  const speakText = (text) => {
    if (synthRef.current.speaking) {
      synthRef.current.cancel();
    }

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = 0.9;
    utterance.pitch = 1;
    utterance.volume = 1;
    synthRef.current.speak(utterance);
  };

  const toggleRecording = () => {
    if (!isChatActive) return;

    if (!isRecording) {
      startRecording();
    } else {
      stopRecording();
    }
  };

  const startRecording = () => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      alert('Speech recognition is not supported in your browser.');
      return;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognitionRef.current = new SpeechRecognition();
    recognitionRef.current.continuous = false;
    recognitionRef.current.interimResults = false;

    recognitionRef.current.onstart = () => {
      setIsRecording(true);
      simulateAudioLevel();
    };

    recognitionRef.current.onresult = (event) => {
      const transcript = event.results[0][0].transcript;
      setInput(transcript);
    };

    recognitionRef.current.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      setIsRecording(false);
      setAudioLevel(0);
    };

    recognitionRef.current.onend = () => {
      setIsRecording(false);
      setAudioLevel(0);
    };

    recognitionRef.current.start();
  };

  const stopRecording = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
  };

  const simulateAudioLevel = () => {
    if (isRecording) {
      setAudioLevel(Math.random() * 100);
      setTimeout(simulateAudioLevel, 100);
    }
  };

  const toggleSpeaking = () => {
    if (!isChatActive) return;
    
    if (isSpeaking) {
      synthRef.current.cancel();
    }
    setIsSpeaking(!isSpeaking);
  };

  const toggleChat = () => {
    if (isChatActive) {
      // End chat
      setMessages([]);
      setInput('');
      contextMemory.current = [];
      setIsRecording(false);
      setIsSpeaking(false);
      if (recognitionRef.current) recognitionRef.current.stop();
      if (synthRef.current) synthRef.current.cancel();
    }
    setIsChatActive(!isChatActive);
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-gray-900 via-blue-900 to-gray-900 text-white p-6">
      <div className="max-w-4xl mx-auto">
        {/* Header */}
        <div className="text-center mb-8">
          <img 
            src="/AvAgAi-Gem.jpg" 
            alt="Avatar Agentic AI Logo" 
            className="w-32 h-32 mx-auto mb-4 rounded-full shadow-2xl border-4 border-blue-400"
            onError={(e) => {
              e.target.style.display = 'none';
            }}
          />
          <h1 className="text-4xl font-bold bg-gradient-to-r from-blue-400 to-purple-400 bg-clip-text text-transparent">
            AVATAR AGENTIC AI Pte Ltd.
          </h1>
        </div>

        {/* Control Panel */}
        <div className="bg-gray-800/50 backdrop-blur-lg rounded-2xl p-6 mb-6 shadow-2xl border border-gray-700">
          <div className="flex items-center justify-center gap-6 mb-6">
            {/* Microphone */}
            <button
              onClick={toggleRecording}
              disabled={!isChatActive}
              className={`p-4 rounded-full transition-all ${
                isRecording 
                  ? 'bg-red-500 hover:bg-red-600 scale-110' 
                  : 'bg-blue-500 hover:bg-blue-600'
              } ${!isChatActive ? 'opacity-50 cursor-not-allowed' : ''}`}
            >
              {isRecording ? <MicOff size={28} /> : <Mic size={28} />}
            </button>

            {/* Voice Level Bar */}
            {isRecording && (
              <div className="flex-1 max-w-xs">
                <div className="h-8 bg-gray-700 rounded-full overflow-hidden">
                  <div 
                    className="h-full bg-gradient-to-r from-green-400 to-blue-500 transition-all duration-100"
                    style={{ width: `${audioLevel}%` }}
                  />
                </div>
              </div>
            )}

            {/* Speaker */}
            <button
              onClick={toggleSpeaking}
              disabled={!isChatActive}
              className={`p-4 rounded-full transition-all ${
                isSpeaking 
                  ? 'bg-green-500 hover:bg-green-600' 
                  : 'bg-gray-500 hover:bg-gray-600'
              } ${!isChatActive ? 'opacity-50 cursor-not-allowed' : ''}`}
            >
              {isSpeaking ? <Volume2 size={28} /> : <VolumeX size={28} />}
            </button>

            {/* Toggle Chat */}
            <button
              onClick={toggleChat}
              className={`px-8 py-3 rounded-full font-semibold transition-all ${
                isChatActive 
                  ? 'bg-red-500 hover:bg-red-600' 
                  : 'bg-green-500 hover:bg-green-600'
              }`}
            >
              {isChatActive ? 'End Chat' : 'Start Chat'}
            </button>
          </div>

          {/* Input Area */}
          <div className="flex gap-3">
            <input
              type="text"
              value={input}
              onChange={(e) => setInput(e.target.value)}
              onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
              placeholder={isChatActive ? "Type your message..." : "Start chat to begin..."}
              disabled={!isChatActive}
              className="flex-1 bg-gray-700/50 border border-gray-600 rounded-lg px-4 py-3 text-white placeholder-gray-400 focus:outline-none focus:border-blue-500 disabled:opacity-50"
            />
            <button
              onClick={handleSendMessage}
              disabled={!isChatActive || !input.trim() || isLoading}
              className="bg-blue-500 hover:bg-blue-600 disabled:bg-gray-600 disabled:cursor-not-allowed p-3 rounded-lg transition-all"
            >
              <Send size={24} />
            </button>
          </div>
        </div>

        {/* Chat Log */}
        <div 
          ref={chatLogRef}
          className="bg-gray-800/50 backdrop-blur-lg rounded-2xl p-6 h-96 overflow-y-auto shadow-2xl border border-gray-700"
        >
          {messages.length === 0 ? (
            <div className="h-full flex items-center justify-center text-gray-400">
              {isChatActive ? 'Start chatting...' : 'Click "Start Chat" to begin'}
            </div>
          ) : (
            <div className="space-y-4">
              {messages.map((msg, idx) => (
                <div
                  key={idx}
                  className={`p-4 rounded-lg ${
                    msg.role === 'user'
                      ? 'bg-blue-600/30 ml-8'
                      : 'bg-purple-600/30 mr-8'
                  }`}
                >
                  <div className="font-semibold mb-1 text-sm">
                    {msg.role === 'user' ? 'You' : 'AI Assistant'}
                  </div>
                  <div className="text-gray-100">{msg.content}</div>
                </div>
              ))}
              {isLoading && (
                <div className="bg-purple-600/30 mr-8 p-4 rounded-lg">
                  <div className="flex gap-2">
                    <div className="w-2 h-2 bg-purple-400 rounded-full animate-bounce" />
                    <div className="w-2 h-2 bg-purple-400 rounded-full animate-bounce delay-100" />
                    <div className="w-2 h-2 bg-purple-400 rounded-full animate-bounce delay-200" />
                  </div>
                </div>
              )}
            </div>
          )}
        </div>

        {/* Instructions */}
        <div className="mt-6 text-center text-sm text-gray-400">
          <p>Note: Ensure your OPEN_AI_KEY environment variable is set for API access</p>
        </div>
      </div>
    </div>
  );
}